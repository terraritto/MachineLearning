# workflow
1. 問題を定義し、データセットを作成  
入力データは何か、予測しようとしてるものは何かを明確にする  
直面している問題はどのような種類かを明確にする.二値分類、多クラス？それとも回帰？  
2. 成功の指標を選択する  
何をもって成功かを定義する、適合率？再現率？  
これは損失関数を選択する目安となる。  
3. 評価プロトコルを決定する  
まあ、ホールドアウトかk-fold覚えとけばあとは選ぶだけで大体行ける  
4. データを準備する  
データをdeep learningに合うようにセットする必要がある。  
データをテンソルに  
スケールは[-1,1],[0,1]のような小さな値にスケール　　
 特徴量によって値が異なるなら正規化  
データ量が少なければ特徴エンジニアリング
5. ベースラインを越える性能のモデルを開発する  
目標精度以上を目指していこう！MNISTなら0.1を越える,映画レビューなら0.5を越えるなど  
成り立たないときもある、その時は1~3の設計から見直す  
上手くいったなら次の3つを選択
* 最後の層の活性化  
ネットわーっくの出力に制限
* 損失関数  
問題の種類に適合
* 最適化の設定  
optimizerは適切に
6. スケールアップ  
必要なのは学習不足と過学習の間の値  
なら過学習は必要だ！！！！  
これは次のことで測れる
* 層を追加
* 層を大きく
* 訓練のepoch数を増やす  
これを適用しつつ、損失値を加えればよい
7. モデルの正規化とハイパーパラメータのチューニング  
* dropout追加  
* 層の追加や削除
* L1/L2正規化を追加  
* 最適な設定を見つけるために(層1積辺りのユニット数やoptimizerの学習率など)別のハイパーパラメータを試す
* 特徴エンジニアリングを繰り返す  
これらにより満足のいく設定となったらなら、テストデータで試す。もしも検証データより大分下なら問題あり